{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tandem Output Analysis\n",
    "\n",
    "This notebook demonstrates how to import and use the `readtandemoutput` function to analyze Tandem simulation outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code by bar oryan \n",
    "# boryan@ucsd.edu\n",
    "import readtandemoutput\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this to read fault outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/bar/GoogleDrive/Scripps/Tandem/randomFaults/old/faultsEveryWhere/0.3/'\n",
    "pattern='fltst_dp*'\n",
    "sperator=None\n",
    "\n",
    "### This function searches the specified path for all files matching a given pattern.\n",
    "### It reads each matching fault output CSV file and combines them into xarray objects.\n",
    "### It returns a list of Fault objects (a custom class used to store the data).\n",
    "###\n",
    "### If multiple faults are present and their names follow a consistent pattern—differentiated\n",
    "### by a separator string—then the function will group them accordingly.\n",
    "### \n",
    "### For example, given files like:\n",
    "###     fltst_dp-westFault-1.csv\n",
    "###     fltst_dp-westFault-2.csv\n",
    "###     fltst_dp-eastFault-1.csv\n",
    "###     fltst_dp-eastFault-2.csv\n",
    "### and a separator of '-', the function will detect two unique faults (\"westFault\" and \"eastFault\")\n",
    "### and return a list with two Fault objects.\n",
    "###\n",
    "### If `separator` is set to None, the function assumes there is only one fault and returns a list\n",
    "### containing a single Fault object.\n",
    "\n",
    "fault=readtandemoutput.ReturnManyFaults(path=path,pattern=pattern,sperator=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can then use this fault object to plot the data\n",
    "fault[0].PlotDataset(quantity='slip-rate0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also directly access the fault data\n",
    "\n",
    "fault[0].dataset['slip-rate0']\n",
    "fault[0].dataset['normal-stress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can also use to the compute EQ catalog\n",
    "\n",
    "paramsToComputeCatalog={\"height\":1e-2,'distance':2000} \n",
    "### These parameters control how the algorithm detects earthquakes (EQs):\n",
    "### - `height` sets the acceleration threshold above which an event is considered an earthquake.\n",
    "### - `distance` defines the minimum number of indices to skip before detecting another possible EQ,\n",
    "###   helping to avoid false positives from closely spaced peaks.\n",
    "###\n",
    "### You should experiment with these values and plot the results to ensure that the magenta dots\n",
    "### (which indicate detected EQs) are correctly placed and consistently aligned across events.\n",
    "###\n",
    "### While there may be more sophisticated approaches, I found that this worked quite okay for me\n",
    "\n",
    "fault[0].ComputeCatalog(paramsToComputeCatalog=paramsToComputeCatalog)\n",
    "\n",
    "\n",
    "fault[0].catalogObject.Plot2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault[0].catalog  # finally looked at the catalog \n",
    "# This is the pandas DataFrame that provides the along-dip extent, moment magnitude (Mw),\n",
    "# onset time of each earthquake (EQ), and the assumed along-strike extent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BTW if you want to make sure the bd you set are accurate you can use this nice package\n",
    "import domainOutput\n",
    "meshFile='my_gmsh_file.msh'\n",
    "mymesh=domainOutput.mesh(meshFile)\n",
    "mymesh.plot_physical_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
